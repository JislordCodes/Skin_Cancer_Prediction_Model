{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JislordCodes/Skin_Cancer_Prediction_Model/blob/main/Skin_Cancer_Prediction_Model%26Test_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcVdbvMSFzd6",
        "outputId": "62fe561c-4869-44aa-ce09-7ac7cd0f6b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TLj56tSTKdQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ387zSV7OkM"
      },
      "outputs": [],
      "source": [
        "# Set the path to your dataset directories\n",
        "training_path = '/content/drive/MyDrive/archive (1)/train'  # Update with your training data path\n",
        "test_path = '/content/drive/MyDrive/archive (1)/test'  # Update with your testing data path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MaNE7a1FBRA"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULwUDNA9aBcC"
      },
      "outputs": [],
      "source": [
        "def process_image(file_path):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def process_path(file_path):\n",
        "    label = tf.strings.split(file_path, '/')[-2]\n",
        "    label = tf.where(label == 'malignant', 1, 0)\n",
        "    img = process_image(file_path)\n",
        "    return img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK-J-32HgyXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a50adc5-b208-4e29-f760-e268085b8230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2787 images belonging to 2 classes.\n",
            "Found 660 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for the test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1weyp8azZJyt"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.list_files(training_path + '/*/*', shuffle=True)\n",
        "train_dataset = train_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(test_path + '/*/*', shuffle=False)\n",
        "test_dataset = test_dataset.map(process_path, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXP3HQxHfqaA"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.cache().shuffle(1000).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luZv3rGYKnAZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, Model, backend as K\n",
        "\n",
        "def pre_activation_residual_block(inputs, num_filters, kernel_size=3, strides=1, activation='relu'):\n",
        "    x = layers.BatchNormalization()(inputs)\n",
        "    x = layers.Activation(activation)(x)\n",
        "    shortcut = x\n",
        "\n",
        "    x = layers.Conv2D(num_filters // 4, 1, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "\n",
        "    x = layers.Conv2D(num_filters // 4, kernel_size, strides=strides, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "\n",
        "    x = layers.Conv2D(num_filters, 1, padding='same', kernel_initializer='he_normal')(x)\n",
        "\n",
        "    if strides != 1 or inputs.shape[-1] != num_filters:\n",
        "        shortcut = layers.Conv2D(num_filters, 1, strides=strides, padding='same', kernel_initializer='he_normal')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    return x\n",
        "\n",
        "def bottleneck_residual_block(inputs, num_filters, kernel_size=3, strides=1, activation='relu'):\n",
        "    x = layers.BatchNormalization()(inputs)\n",
        "    x = layers.Activation(activation)(x)\n",
        "    shortcut = x\n",
        "\n",
        "    x = layers.Conv2D(num_filters // 4, 1, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "\n",
        "    x = layers.Conv2D(num_filters // 4, kernel_size, strides=strides, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "\n",
        "    x = layers.Conv2D(num_filters, 1, padding='same', kernel_initializer='he_normal')(x)\n",
        "\n",
        "    if strides != 1 or inputs.shape[-1] != num_filters:\n",
        "        shortcut = layers.Conv2D(num_filters, 1, strides=strides, padding='same', kernel_initializer='he_normal')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    return x\n",
        "\n",
        "def se_block(inputs, reduction_ratio=16):\n",
        "    channels = K.int_shape(inputs)[-1]\n",
        "    x = layers.GlobalAveragePooling2D()(inputs)\n",
        "    x = layers.Dense(channels // reduction_ratio, activation='relu')(x)\n",
        "    x = layers.Dense(channels, activation='sigmoid')(x)\n",
        "    x = layers.Reshape((1, 1, channels))(x)\n",
        "    return layers.multiply([inputs, x])\n",
        "\n",
        "def resnet(input_shape, num_classes, num_blocks, num_filters=64, activation='relu', block_type='bottleneck'):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(num_filters, 7, strides=2, padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    block_fn = bottleneck_residual_block if block_type == 'bottleneck' else pre_activation_residual_block\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        num_filters *= 2\n",
        "        x = block_fn(x, num_filters, strides=2 if i == 0 else 1, activation=activation)\n",
        "        x = se_block(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHyXd680H-Q_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEdIdTLGUj2z"
      },
      "outputs": [],
      "source": [
        "model = resnet(input_shape=(224, 224, 3), num_classes=2, num_blocks=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=AdamW(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, verbose=1, mode='min', min_lr=0.00001),\n",
        "    EarlyStopping(monitor='loss', patience=15, verbose=1)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKRoUKQtdjb-",
        "outputId": "752e0a0a-6586-4db8-893f-adf4d1d2584b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "88/88 [==============================] - 47s 429ms/step - loss: 0.6716 - accuracy: 0.6053 - val_loss: 0.6895 - val_accuracy: 0.5045 - lr: 1.0000e-05\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 35s 401ms/step - loss: 0.6009 - accuracy: 0.6968 - val_loss: 0.6614 - val_accuracy: 0.6076 - lr: 1.0000e-05\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 35s 399ms/step - loss: 0.5704 - accuracy: 0.7130 - val_loss: 0.6238 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 35s 399ms/step - loss: 0.5465 - accuracy: 0.7252 - val_loss: 0.5693 - val_accuracy: 0.6227 - lr: 1.0000e-05\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 36s 411ms/step - loss: 0.5302 - accuracy: 0.7295 - val_loss: 0.5080 - val_accuracy: 0.6970 - lr: 1.0000e-05\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 36s 407ms/step - loss: 0.5188 - accuracy: 0.7298 - val_loss: 0.4702 - val_accuracy: 0.7530 - lr: 1.0000e-05\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 34s 391ms/step - loss: 0.5115 - accuracy: 0.7338 - val_loss: 0.4564 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 37s 425ms/step - loss: 0.4983 - accuracy: 0.7470 - val_loss: 0.4507 - val_accuracy: 0.7818 - lr: 1.0000e-05\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 36s 411ms/step - loss: 0.4901 - accuracy: 0.7549 - val_loss: 0.4433 - val_accuracy: 0.7773 - lr: 1.0000e-05\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 35s 396ms/step - loss: 0.4846 - accuracy: 0.7474 - val_loss: 0.4404 - val_accuracy: 0.7833 - lr: 1.0000e-05\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 36s 406ms/step - loss: 0.4789 - accuracy: 0.7492 - val_loss: 0.4380 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 36s 407ms/step - loss: 0.4750 - accuracy: 0.7560 - val_loss: 0.4337 - val_accuracy: 0.7833 - lr: 1.0000e-05\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 39s 440ms/step - loss: 0.4703 - accuracy: 0.7585 - val_loss: 0.4292 - val_accuracy: 0.7758 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 36s 410ms/step - loss: 0.4714 - accuracy: 0.7574 - val_loss: 0.4246 - val_accuracy: 0.7833 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 35s 397ms/step - loss: 0.4683 - accuracy: 0.7560 - val_loss: 0.4250 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 36s 413ms/step - loss: 0.4687 - accuracy: 0.7517 - val_loss: 0.4226 - val_accuracy: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 36s 404ms/step - loss: 0.4683 - accuracy: 0.7510 - val_loss: 0.4251 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 35s 393ms/step - loss: 0.4663 - accuracy: 0.7607 - val_loss: 0.4204 - val_accuracy: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 38s 430ms/step - loss: 0.4585 - accuracy: 0.7585 - val_loss: 0.4223 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 35s 392ms/step - loss: 0.4571 - accuracy: 0.7657 - val_loss: 0.4230 - val_accuracy: 0.7864 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 34s 392ms/step - loss: 0.4576 - accuracy: 0.7646 - val_loss: 0.4148 - val_accuracy: 0.7909 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 37s 423ms/step - loss: 0.4508 - accuracy: 0.7786 - val_loss: 0.4179 - val_accuracy: 0.7909 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 35s 399ms/step - loss: 0.4500 - accuracy: 0.7725 - val_loss: 0.4143 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 37s 416ms/step - loss: 0.4515 - accuracy: 0.7722 - val_loss: 0.4166 - val_accuracy: 0.7924 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 37s 426ms/step - loss: 0.4429 - accuracy: 0.7822 - val_loss: 0.4205 - val_accuracy: 0.7939 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 35s 397ms/step - loss: 0.4461 - accuracy: 0.7757 - val_loss: 0.4101 - val_accuracy: 0.7909 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 35s 393ms/step - loss: 0.4459 - accuracy: 0.7790 - val_loss: 0.4085 - val_accuracy: 0.8015 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 35s 404ms/step - loss: 0.4400 - accuracy: 0.7815 - val_loss: 0.4104 - val_accuracy: 0.8015 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 35s 392ms/step - loss: 0.4411 - accuracy: 0.7786 - val_loss: 0.4176 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 35s 402ms/step - loss: 0.4428 - accuracy: 0.7811 - val_loss: 0.4152 - val_accuracy: 0.7924 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 38s 432ms/step - loss: 0.4405 - accuracy: 0.7829 - val_loss: 0.4117 - val_accuracy: 0.8015 - lr: 1.0000e-05\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 37s 416ms/step - loss: 0.4391 - accuracy: 0.7815 - val_loss: 0.4090 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 35s 400ms/step - loss: 0.4383 - accuracy: 0.7793 - val_loss: 0.4054 - val_accuracy: 0.7985 - lr: 1.0000e-05\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 35s 400ms/step - loss: 0.4355 - accuracy: 0.7897 - val_loss: 0.4068 - val_accuracy: 0.7970 - lr: 1.0000e-05\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 35s 397ms/step - loss: 0.4306 - accuracy: 0.7844 - val_loss: 0.4065 - val_accuracy: 0.7985 - lr: 1.0000e-05\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 36s 403ms/step - loss: 0.4368 - accuracy: 0.7840 - val_loss: 0.4075 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 36s 412ms/step - loss: 0.4308 - accuracy: 0.7844 - val_loss: 0.4095 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 35s 395ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4095 - val_accuracy: 0.7970 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 35s 397ms/step - loss: 0.4265 - accuracy: 0.7944 - val_loss: 0.4031 - val_accuracy: 0.7970 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 35s 397ms/step - loss: 0.4337 - accuracy: 0.7797 - val_loss: 0.4121 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 35s 400ms/step - loss: 0.4291 - accuracy: 0.7872 - val_loss: 0.4022 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 37s 415ms/step - loss: 0.4252 - accuracy: 0.7915 - val_loss: 0.4037 - val_accuracy: 0.8015 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 36s 414ms/step - loss: 0.4230 - accuracy: 0.7944 - val_loss: 0.4184 - val_accuracy: 0.7970 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 35s 394ms/step - loss: 0.4354 - accuracy: 0.7872 - val_loss: 0.4188 - val_accuracy: 0.7970 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 37s 424ms/step - loss: 0.4290 - accuracy: 0.7844 - val_loss: 0.3968 - val_accuracy: 0.8030 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 35s 396ms/step - loss: 0.4292 - accuracy: 0.7905 - val_loss: 0.4031 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 35s 403ms/step - loss: 0.4304 - accuracy: 0.7836 - val_loss: 0.3994 - val_accuracy: 0.8061 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 34s 392ms/step - loss: 0.4213 - accuracy: 0.7933 - val_loss: 0.4053 - val_accuracy: 0.7985 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 35s 403ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.4058 - val_accuracy: 0.8030 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 37s 427ms/step - loss: 0.4216 - accuracy: 0.7994 - val_loss: 0.4061 - val_accuracy: 0.8015 - lr: 1.0000e-05\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.4061 - accuracy: 0.8015\n",
            "Test Accuracy: 80.15%\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=60,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx68dxu6TWxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "86286cfa-aa0f-4aa0-f554-f4ba99bc0091"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2be63c04b1fb>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "\n",
        "# Plot training loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Loss:\", test_loss)"
      ],
      "metadata": {
        "id": "GWA9gE_-bxAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db69bedc-c927-422a-ce20-a06a2ae1f1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 4s 135ms/step - loss: 0.3981 - accuracy: 0.8091\n",
            "Test Accuracy: 0.8090909123420715\n",
            "Test Loss: 0.3980783224105835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model3.h5\")"
      ],
      "metadata": {
        "id": "LBJX3wxXb1du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Er4BEPeidi"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}